#!/usr/bin/env python3

"""
Generate view definitions for queries that are written to the
public data project and execute them. Views are published to
an internal project so that data is also accessible in private
datasets.
"""

from argparse import ArgumentParser
import os
import sys
import yaml

from google.cloud import bigquery

# sys.path needs to be modified to enable package imports from parent
# and sibling directories. Also see:
# https://stackoverflow.com/questions/6323860/sibling-package-imports/23542795#23542795
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from bigquery_etl.parse_metadata import Metadata  # noqa E402


METADATA_FILE = "metadata.yaml"


parser = ArgumentParser(description=__doc__)
parser.add_argument(
    "--target",
    nargs="+",
    help="File or directory containing query definitions and metadata",
)
parser.add_argument("--target-project", help="Create views in the target project")
parser.add_argument(
    "--public-project",
    default="mozilla-public-data",
    help=("Project with publicly available data"),
)
parser.add_argument(
    "--dry_run",
    "--dry-run",
    action="store_true",
    help="Validate view definitions, but do not publish them.",
)


def is_public_bigquery(metadata_file):
    """
    Reads the metadata file associated with the query to determine if the query 
    results should be written into the public dataset.
    """

    try:
        metadata = Metadata.from_file(metadata_file)
        return metadata.is_public_bigquery()
    except yaml.YAMLError as e:
        print(e)
    except FileNotFoundError as e:
        print("Metadata file does not exist: {}", e)

    return False


def generate_and_publish_view(client, project, dataset, table, public_project, dry_run):
    """
    Generates view definitions for public data and executes them.
    """

    full_view_id = ".".join([project, dataset, table])
    public_table = ".".join([public_project, dataset, table])

    view_sql = f"""CREATE OR REPLACE VIEW 
        `{full_view_id}`
    AS SELECT * FROM `{public_table}`
    """

    job_config = bigquery.QueryJobConfig(use_legacy_sql=False, dry_run=dry_run)
    client.query(view_sql, job_config)


def main():
    args = parser.parse_args()
    target_project = args.target_project
    client = bigquery.Client(target_project)

    for target in args.target:
        if os.path.isdir(target):
            for root, dirs, files in os.walk(target):
                if METADATA_FILE in files:
                    metadata_file = os.path.join(root, METADATA_FILE)

                    if is_public_bigquery(metadata_file):
                        path = os.path.normpath(root)
                        dataset = path.split(os.sep)[-2]
                        table = path.split(os.sep)[-1]

                        generate_and_publish_view(
                            client,
                            target_project,
                            dataset,
                            table,
                            args.public_project,
                            args.dry_run,
                        )


if __name__ == "__main__":
    main()
