#!/bin/bash

set -e

cd "$(dirname "$0")/../.."

project=moz-fx-data-shared-prod
dataset=org_mozilla_fenix_stable
# e.g. baseline_v1
tables=$(bq ls --format=json $project:$dataset | \
        jq -r '.[] | .tableReference.tableId')

function write_scalars {
    local table=$1
    local directory="sql/glam_etl/fenix_clients_daily_scalar_aggregates_${table}"
    mkdir -p "$directory"
    if ! python3 -m bigquery_etl.glam.clients_daily_scalar_aggregates \
        --source-table "$dataset.$table" \
        > "$directory/query.sql"; then
            echo "skipping $directory/query.sql: no probes found"
            rm -r "$directory"
    else
        echo "generated $directory/query.sql"
    fi
}

function write_histograms {
    local table=$1
    local directory="sql/glam_etl/fenix_clients_daily_histogram_aggregates_${table}"
    mkdir -p "$directory"
    if ! python3 -m bigquery_etl.glam.clients_daily_histogram_aggregates \
        --source-table "$dataset.$table" \
        > "$directory/query.sql"; then
            echo "skipping $directory/query.sql: no probes found"
            rm -r "$directory"
    else
        echo "generated $directory/query.sql"
    fi
}

function write_clients_daily_aggregates {
    for table in $tables; do
        write_scalars "$table"
        write_histograms "$table"
    done
}

function latest_versions {
  directory="sql/glam_etl/fenix_latest_versions_v1"
  mkdir -p "$directory"
  python -m bigquery_etl.glam.latest_versions \
      --source "${dataset}.baseline_v1" \
      > $directory/query.sql
  echo "generated $directory/query.sql"
}

function write_clients_aggregates {
    directory="sql/glam_etl/fenix_clients_scalar_aggregates_v1"
    mkdir -p "$directory"
    python -m bigquery_etl.glam.scalar_aggregates_incremental \
        --init \
        --ping-type glean \
        --destination glam_etl.fenix_clients_scalar_aggregates_v1 \
        > $directory/init.sql
    echo "generated $directory/init.sql"

    python -m bigquery_etl.glam.scalar_aggregates_incremental \
        --ping-type glean \
        --source glam_etl.fenix_view_clients_daily_scalar_aggregates_v1 \
        --destination glam_etl.fenix_clients_scalar_aggregates_v1 \
        > $directory/query.sql
    echo "generated $directory/query.sql"

    # write histograms
    directory="sql/glam_etl/fenix_clients_histogram_aggregates_v1"
    mkdir -p "$directory"
    python -m bigquery_etl.glam.clients_histogram_aggregates \
        --init \
        > $directory/init.sql
    echo "generated $directory/init.sql"

    python -m bigquery_etl.glam.clients_histogram_aggregates \
        > $directory/query.sql
    echo "generated $directory/query.sql"
}

function write_scalar_bucket_counts {
    directory="sql/glam_etl/fenix_clients_scalar_bucket_counts_v1"
    mkdir -p "$directory"
    python -m bigquery_etl.glam.bucket_counts \
        --ping-type glean \
        > $directory/query.sql
    echo "generated $directory/query.sql"
}

function write_scalar_probe_counts {
    directory="sql/glam_etl/fenix_clients_scalar_probe_counts_v1"
    mkdir -p "$directory"
    python -m bigquery_etl.glam.probe_counts \
        --ping-type glean \
        --source-table "glam_etl.fenix_clients_scalar_bucket_counts_v1" \
        > $directory/query.sql
    echo "generated $directory/query.sql"
}

function write_scalar_percentiles {
    directory="sql/glam_etl/fenix_scalar_percentiles_v1"
    mkdir -p "$directory"
    python -m bigquery_etl.glam.scalar_percentiles \
        --ping-type glean \
        > $directory/query.sql
    echo "generated $directory/query.sql"
}

function write_histogram_bucket_counts {
    directory="sql/glam_etl/fenix_clients_histogram_bucket_counts_v1"
    mkdir -p "$directory"
    python -m bigquery_etl.glam.clients_histogram_bucket_counts \
        > $directory/query.sql
    echo "generated $directory/query.sql"
}

function write_histogram_probe_counts {
    directory="sql/glam_etl/fenix_clients_histogram_probe_counts_v1"
    mkdir -p "$directory"
    python -m bigquery_etl.glam.probe_counts \
        --ping-type glean \
        --source-table "glam_etl.fenix_clients_histogram_bucket_counts_v1" \
        --histogram \
        > $directory/query.sql
    echo "generated $directory/query.sql"
}

# function write_histogram_percentiles {
#     directory="sql/glam_etl/fenix_histogram_percentiles_v1"
#     mkdir -p "$directory"
#     python -m bigquery_etl.glam.histogram_percentiles \
#         --ping-type glean \
#         > $directory/query.sql
#     echo "generated $directory/query.sql"
# }


start_stage=${START_STAGE:-0}
if ((start_stage <= 0)); then write_clients_daily_aggregates; fi
if ((start_stage <= 1)); then
    write_clients_aggregates
    latest_versions

    write_scalar_bucket_counts
    write_scalar_probe_counts
    write_scalar_percentiles

    write_histogram_bucket_counts
    write_histogram_probe_counts
    # write_histogram_percentiles
fi
