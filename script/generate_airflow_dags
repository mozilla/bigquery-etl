#!/bin/sh

# Generate Airflow DAGs.
#
# Generated DAGs are by default written to the dags/ directory.


cd "$(dirname "$0")/.."

if ! which javac >/dev/null && which docker >/dev/null; then
    # run in docker where javac is available
    docker run --tty --interactive --rm \
      --volume $PWD/bigquery_etl:/app/bigquery_etl \
      --volume $PWD/sql:/app/sql \
      --volume $PWD/dags:/app/dags \
      --volume $PWD/dags.yaml:/app/dags.yaml \
      mozilla/bigquery-etl:relud \
      bash -c 'python3 -m bigquery_etl.query_scheduling.generate_airflow_dags "$@"' -s "$@"
else
    python3 -m bigquery_etl.query_scheduling.generate_airflow_dags "$@"
fi
