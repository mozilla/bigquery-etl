---
version: 2.1

orbs:
  gcp-gcr: circleci/gcp-gcr@0.13.0
  docker: circleci/docker@1.5

jobs:
  build:
    docker: &docker
      - image: python:3.8
    steps:
      - checkout
      - &restore_venv_cache
        restore_cache:
          keys:
            # when lock files change, use increasingly general
            # patterns to restore cache
            - &python_cache_key
              # yamllint disable-line rule:line-length
              python-3.8-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-{{ checksum "requirements.txt" }}
              # yamllint disable-line rule:line-length
            - python-3.8-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-
            - python-3.8-packages-v1-{{ .Branch }}-
            - python-3.8-packages-v1-main-
      - &build
        run:
          name: Build
          command: |
            python3.8 -m venv venv/
            venv/bin/pip install pip-tools --constraint requirements.in
            venv/bin/pip-sync
      - run:
          name: Yamllint Test
          command: PATH="venv/bin:$PATH" yamllint -c .yamllint.yaml .
      - run:
          name: PyTest with linters
          # integration and java tests are run in a separate `integration` step;
          # SQL and routine tests are split out into a separate `test-sql` test
          # since those tests take the longest to run and running those tests
          # in parallel speeds up CI
          command: |
            PATH="venv/bin:$PATH" script/entrypoint --black --flake8 \
              --mypy-ignore-missing-imports --pydocstyle \
              -m "not (routine or sql or integration or java)" \
              -n 8
      - save_cache:
          paths:
            - venv/
          key: *python_cache_key
  verify-format-sql:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - &attach_generated_sql
        attach_workspace:
          at: /tmp/workspace
      - &copy_generated_sql
        run:
          name: Move generated-sql into place
          command: |
            rm -rf sql/
            cp -r /tmp/workspace/generated-sql/sql sql
      - run:
          name: Verify that SQL is correctly formatted
          command: |
            PATH="venv/bin:$PATH" script/bqetl format --check \
            $(git ls-tree -d HEAD --name-only)
  verify-requirements:
    docker: *docker
    steps:
      - checkout
      - run:
          name: Verify that requirements.txt contains the right dependencies for
            this python version
          # use `--constraint` with `requirements.in` not `requirements.txt`
          # because for pip>=20.3 "Constraints are only allowed to take the form
          # of a package name and a version specifier"
          command: |
            pip install pip-tools --constraint requirements.in
            pip-compile --quiet --allow-unsafe --generate-hashes
            pip-compile --quiet --allow-unsafe --generate-hashes \
              java-requirements.in
            git diff --exit-code -G '^ *[^# ]' -- requirements.txt \
              java-requirements.txt
  test-sql:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - *attach_generated_sql
      - *copy_generated_sql
      - run:
          name: Run SQL tests
          command: |
            if [ -n "$CIRCLE_PR_NUMBER" ]; then
              echo "Cannot pass creds to forked PRs," \
                "so skipping routine and SQL tests"
            else
              PATH="venv/bin:$PATH" script/entrypoint -m "routine or sql" -n 8
            fi
  dry-run-sql:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - *attach_generated_sql
      - *copy_generated_sql
      - run:
          name: Dry run queries
          # yamllint disable rule:line-length
          command: |
            if [ "$CIRCLE_BRANCH" = main ]; then
              echo "Check dry run for all queries because branch is" \
                "$CIRCLE_BRANCH"
              PATHS=sql
            elif git log --format=%B --no-merges -n 1 |
                grep -qF '[run-tests]'; then
              echo "Check dry run for all queries because [run-tests] in" \
                "commit message"
              PATHS=sql
            else
              echo "Check dry run for modified queries"
              PATHS="$(git diff origin/main... --name-only --diff-filter=d -- sql)"
            fi
            echo $PATHS
            PATH="venv/bin:$PATH" script/dryrun --validate-schemas $PATHS
          # yamllint enable rule:line-length
  validate-metadata:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - *attach_generated_sql
      - *copy_generated_sql
      - run:
          name: Verify that metadata files are valid
          command: PATH="venv/bin:$PATH" script/validate_metadata
  integration:
    docker: *docker
    steps:
      - checkout
      - &skip_forked_pr
        run:
          name: Early return if this build is from a forked PR
          command: |
            if [ -n "$CIRCLE_PR_NUMBER" ]; then
              echo "Cannot pass creds to forked PRs," \
                "so marking this step successful"
              circleci-agent step halt
            fi
      - *restore_venv_cache
      - *build
      - &restore_mvn_cache
        restore_cache:
          keys:
            # when lock files change, use increasingly general
            # patterns to restore cache
            - &mvn_cache_key
              maven-packages-v1-{{ .Branch }}-{{ checksum "pom.xml" }}
            - maven-packages-v1-{{ .Branch }}-
            - maven-packages-v1-main-
      - &java_deps
        run:
          name: Install maven and java and download dependencies
          command: |
            apt update
            apt install -y maven default-jdk-headless
            mvn dependency:copy-dependencies
            venv/bin/pip-sync requirements.txt java-requirements.txt
      - run:
          name: PyTest Integration Test
          # Google's client libraries will check for
          # GOOGLE_APPLICATION_CREDENTIALS
          # and use a file in that location for credentials if present;
          # See https://cloud.google.com/docs/authentication/production
          # yamllint disable rule:line-length
          command: |
            export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"
            echo "$GCLOUD_SERVICE_KEY" > "$GOOGLE_APPLICATION_CREDENTIALS"
            PATH="venv/bin:$PATH" script/entrypoint -m 'integration or java' -n 8
          # yamllint enable rule:line-length
      - save_cache:
          paths:
            - ~/.m2
          key: *mvn_cache_key
  generate-dags:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - *restore_mvn_cache
      - *java_deps
      - *attach_generated_sql
      - *copy_generated_sql
      - run:
          name: Generate DAGs
          command: PATH="venv/bin:$PATH" script/generate_airflow_dags
      # this task is overwriting the content produced by generate-sql;
      # the behaviour here is additive, generated DAGs are just added to
      # the generated-sql output
      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - generated-sql
  validate-dags:
    # based on
    # https://github.com/mozilla/telemetry-airflow/blob/main/.circleci/config.yml
    machine:
      image: ubuntu-1604:201903-01
      docker_layer_caching: true
    steps:
      - checkout
      - run:
          name: Early return when job not modified
          command: |
            if [ "$CIRCLE_BRANCH" = main ]; then
              echo "Run job because branch is $CIRCLE_BRANCH"
            elif git log --format=%B --no-merges -n 1 |
                grep -qF '[run-tests]'; then
              echo "Run job because [run-tests] in commit message"
            elif ! git diff --quiet origin/main... \
                -- "$(git rev-parse --show-toplevel)"/{.circleci,dags}; then
              echo "Run job because .circleci/ and/or dags/ were modified" \
                "since branching off main"
            else
              echo "Skipping job because .circleci/ and dags/ were not modified"
              circleci-agent step halt
            fi
      - run:
          name: Pull telemetry-airflow
          command: |
            git clone https://github.com/mozilla/telemetry-airflow.git
            cp -a dags/. telemetry-airflow/dags/
      - *attach_generated_sql
      - *copy_generated_sql
      - run:
          command: |
            cd telemetry-airflow
            docker-compose pull
            docker-compose build
            # now take ownership of the folder
            sudo chown -R 10001:10001 .
      - run:
          name: Test if dag scripts can be parsed
          command: |
            cd telemetry-airflow
            bash bin/test-parse
  verify-dags-up-to-date:
    # todo: remove this step once we rely on generate-dags completely
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - *restore_mvn_cache
      - *java_deps
      - run:
          name: Generate DAGs
          command: PATH="venv/bin:$PATH" script/generate_airflow_dags
      - run:
          name: Verify that DAGs were correctly generated and are up-to-date
          command: |
            git diff --exit-code
            diff <(git ls-files dags/*.py) <(ls dags/*.py)
  validate-docs:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - *attach_generated_sql
      - *copy_generated_sql
      - run:
          name: Validate doc examples
          command: PATH="venv/bin:$PATH" script/validate_docs
  validate-views:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - *restore_mvn_cache
      - *java_deps
      - *attach_generated_sql
      - *copy_generated_sql
      - run:
          name: Validate views
          command: PATH="venv/bin:$PATH" script/bqetl view validate
  docs:
    docker: *docker
    steps:
      - checkout
      - *skip_forked_pr
      - *restore_venv_cache
      - *build
      - *restore_mvn_cache
      - *java_deps
      - *attach_generated_sql
      - add_ssh_keys:
          fingerprints: "ab:b5:f7:55:92:0a:72:c4:63:0e:57:be:cd:66:32:53"
      - run:
          name: Build and deploy docs
          command: |
            rm -r sql/ && cp -r /tmp/workspace/generated-sql/sql sql/
            PATH="venv/bin:$PATH" script/generate_docs \
               --output_dir=generated_docs/
            cd generated_docs/
            PATH="../venv/bin:$PATH" mkdocs gh-deploy \
              -m "[ci skip] Deployed {sha} with MkDocs version: {version}"
  generate-sql:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - *restore_mvn_cache
      - *java_deps
      - run:
          name: Generate SQL content
          command: |
            mkdir -p /tmp/workspace/generated-sql
            cp -r sql/ /tmp/workspace/generated-sql/sql
            # Don't depend on dry run for PRs
            PATH="venv/bin:$PATH" script/bqetl generate all \
              --output-dir /tmp/workspace/generated-sql/sql/ \
              --target-project moz-fx-data-shared-prod
            PATH="venv/bin:$PATH" script/bqetl dependency record \
              --skip-existing \
              "/tmp/workspace/generated-sql/sql/"
      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - generated-sql
  push-generated-sql:
    docker: *docker
    steps:
      - *attach_generated_sql
      - add_ssh_keys:
          fingerprints: "ab:b5:f7:55:92:0a:72:c4:63:0e:57:be:cd:66:32:53"
      - run:
          name: Push to generated-sql branch
          command: |
            ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
            git config --global user.name "CircleCI generate-sql job"
            git config --global user.email "dataops+generated-sql@mozilla.com"
            git clone --single-branch --branch generated-sql \
              git@github.com:mozilla/bigquery-etl \
              generated-sql
            cd generated-sql/
            rm -rf sql/
            cp -r /tmp/workspace/generated-sql/sql sql
            git add .
            git commit -m "Auto-push due to change on main branch [ci skip]" \
              && git push \
              || echo "Skipping push since it looks like there were no changes"

  deploy:
    executor: docker/docker
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: true
      - *attach_generated_sql
      - *copy_generated_sql
      - when:
          condition: &deploy-condition
            or:
              - equal: [main, << pipeline.git.branch >>]
              - << pipeline.git.tag >>
          steps:
            - docker/check:
                docker-password: DOCKER_PASS
                docker-username: DOCKER_USER
      - docker/build: &public-image
          image: ${CIRCLE_PROJECT_USERNAME+$CIRCLE_PROJECT_USERNAME/}${CIRCLE_PROJECT_REPONAME:-bigquery-etl}
          tag: ${CIRCLE_TAG:-latest}
      - when:
          condition: *deploy-condition
          steps:
            - docker/push: *public-image
  private-generate-sql:
    docker: *docker
    steps:
      - checkout
      - *skip_forked_pr
      - *restore_venv_cache
      - *build
      - *restore_mvn_cache
      - *java_deps
      - add_ssh_keys:
          # deploy key to private-bigquery-etl
          fingerprints: "cf:d6:25:9a:ee:26:66:39:c8:cc:48:f6:bb:3e:34:68"
      - run:
          name: Install rsync
          command: |
            apt update
            apt install -y rsync
      - run:
          name: Pull down private SQL content
          command: |
            ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
            git clone --single-branch --branch main \
                          git@github.com:mozilla/private-bigquery-etl.git \
                          ~/private-bigquery-etl
            rsync --archive ~/private-bigquery-etl/sql/ sql/
      - run:
          name: Generate SQL content
          command: |
            mkdir -p /tmp/workspace/private-generated-sql
            cp -r sql/ /tmp/workspace/private-generated-sql/sql
            # Don't depend on dry run for PRs
            PATH="venv/bin:$PATH" script/bqetl generate all \
              --output-dir /tmp/workspace/private-generated-sql/sql/ \
              --target-project moz-fx-data-shared-prod
      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - private-generated-sql
  push-private-generated-sql:
    docker: *docker
    steps:
      - *attach_generated_sql
      - add_ssh_keys:
          fingerprints: "cf:d6:25:9a:ee:26:66:39:c8:cc:48:f6:bb:3e:34:68"
      - run:
          name: Push to private-generated-sql branch
          # yamllint disable rule:line-length
          command: |
            ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
            git config --global user.name "CircleCI private-generate-sql job"
            git config --global user.email "dataops+private-generated-sql@mozilla.com"
            git clone --single-branch --branch private-generated-sql \
              git@github.com:mozilla/private-bigquery-etl \
              private-generated-sql
            cd private-generated-sql/
            rm -rf sql/
            cp -r /tmp/workspace/private-generated-sql/sql sql
            git add .
            git commit -m "Auto-push due to change on main branch [ci skip]" \
              && git push \
              || echo "Skipping push since it looks like there were no changes"
          # yamllint enable rule:line-length
  deploy-to-private-gcr:
    executor: gcp-gcr/default
    steps:
      - checkout
      - *attach_generated_sql
      - *copy_generated_sql
      - when:
          condition: *deploy-condition
          steps:
            - gcp-gcr/gcr-auth
      - gcp-gcr/build-image: &private-image
          image: bigquery-etl
          tag: ${CIRCLE_TAG:-latest}
      - when:
          condition: *deploy-condition
          steps:
            - gcp-gcr/push-image: *private-image
  generate-diff:
    docker: *docker
    steps:
      - checkout
      - attach_workspace:
          at: /tmp/workspace
      - *restore_venv_cache
      - *build
      - *restore_mvn_cache
      - *java_deps
      - run:
          name: Generate SQL content diff
          command: |
            # compare a branch against the main branch,
            # or skip if we're already on the main branch
            if [[ "$CIRCLE_BRANCH" == "main" ]]; then
              circleci-agent step halt
            fi
            git clone --single-branch --branch main \
              git@github.com:mozilla/bigquery-etl \
              bigquery-etl-main

            cd bigquery-etl-main
            pip install -r requirements.txt
            pip install -r java-requirements.txt
            mvn dependency:copy-dependencies
            ./script/generate_sql \
              --target-project moz-fx-data-shared-prod

            cd ..
            diff -bur --no-dereference \
              bigquery-etl-main/sql/ /tmp/workspace/generated-sql/sql/ \
              > /tmp/workspace/generated-sql/sql.diff || true
      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - generated-sql
  post-diff:
    docker:
      - image: circleci/node:8.10.0
    steps:
      - checkout
      - attach_workspace:
          at: /tmp/workspace
      - run: npm i circle-github-bot
      - run: .circleci/post-diff.js
      - store_artifacts:
          path: /tmp/integration
          destination: /app/integration
  manual-trigger-required-for-fork:
    docker: *docker
    steps:
      - &skip_upstream
        run:
          name: Early return if this build is running on upstream
          command: |
            if [ -n "$CIRCLE_PR_NUMBER" ]; then
              echo "Build on fork"
            else
              echo "Build on upstream"
              circleci-agent step halt
            fi
      - checkout
      - run:
          name: Manually trigger integration tests for fork
          # yamllint disable rule:line-length
          command: |
            apt update
            apt install jq -y

            CIRCLE_PR_BRANCH=`curl -s https://api.github.com/repos/${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}/pulls/${CIRCLE_PR_NUMBER} | jq -r '.head.label'`

            echo "Integration tests for this fork need to be triggered manually"
            echo "Users with write access to the repository can trigger" \
              "integration tests by visiting: "
            echo "https://github.com/mozilla/bigquery-etl/actions/workflows/push-to-upstream.yml".
            echo "Trigger via 'Run workflow' and provide '$CIRCLE_PR_BRANCH' as parameter."

            exit 1
          # yamllint enable rule:line-length

workflows:
  version: 2
  build:
    jobs: &build_jobs
      - manual-trigger-required-for-fork
      - build:
          context: data-eng-circleci-tests
      - verify-format-sql:
          requires:
            - generate-sql
      - verify-requirements
      - test-sql:
          context: data-eng-circleci-tests
          requires:
            - generate-sql
      - dry-run-sql:
          requires:
            - generate-sql
      - validate-metadata:
          requires:
            - generate-sql
      - integration
      - validate-dags:
          requires:
            - generate-dags
      - verify-dags-up-to-date
      - validate-docs:
          requires:
            - generate-sql
      - validate-views:
          requires:
            - generate-sql
      - generate-sql
      - generate-diff:
          requires:
            - generate-sql
          filters:
            branches:
              ignore: main
      - post-diff:
          requires:
            - generate-diff
          filters:
            branches:
              ignore: main
      - generate-dags:
          requires:
            - generate-sql
      - docs:
          requires:
            - generate-sql
          filters:
            branches:
              only: main
      - push-generated-sql:
          requires:
            - generate-sql
          filters:
            branches:
              only:
                - main
      - deploy:
          context: data-eng-bigquery-etl-dockerhub
          requires:
            - generate-sql
            # Public image must be pushed after the private one because of
            # webhooks used in Ops logic. For details, see:
            # https://bugzilla.mozilla.org/show_bug.cgi?id=1715628#c0
            - deploy-to-private-gcr
      # The following "private" jobs are basically clones of the public jobs
      # for generate-sql, deploy, and push-generated-sql, except that they pull
      # in some additional content from an internal Mozilla repository for
      # cases where ETL code cannot be public. Although the CI logic is
      # consolidated in this public repository, note that we are both pulling
      # from the internal repository and pushing generated results back to
      # a branch on that internal repository, which may be initially
      # surprising.
      - private-generate-sql
      - push-private-generated-sql:
          requires:
            - private-generate-sql
          filters:
            branches:
              only:
                - main
      - deploy-to-private-gcr:
          context: data-eng-airflow-gcr
          requires:
            - private-generate-sql
            # can't run in parallel because CIRCLE_BUILD_NUM is same
            - build
            - generate-sql
