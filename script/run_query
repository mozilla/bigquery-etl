#!/usr/bin/env python3

"""
Runs SQL queries and writes results to destination tables.

When executing a query associated metadata is parsed to determine whether
results should be written to a corresponding public dataset.
"""

from argparse import ArgumentParser
import os
import re
import subprocess
import sys
import yaml


# sys.path needs to be modified to enable package imports from parent
# and sibling directories. Also see:
# https://stackoverflow.com/questions/6323860/sibling-package-imports/23542795#23542795
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from bigquery_etl.parse_metadata import Metadata  # noqa E402


PROJECT_ID_ARG_RE = re.compile(fr"(--project_id=)(\s?[a-zA-z0-9_-]+)")

parser = ArgumentParser(description=__doc__)
parser.add_argument(
    "--public_project_id",
    default="mozilla-public-data",
    help="Project with publicly accessible data",
)
parser.add_argument("--query_file", help="File path to query to be executed")


def main():
    args, query_arguments = parser.parse_known_args()
    query_arguments = query_arguments[0]
    query_file = args.query_file

    try:
        metadata = Metadata.of_sql_file(query_file)
        if metadata.is_public_bigquery(args.query_file):
            # change the project ID to write results to the public dataset
            # a view to the public table in the internal dataset is created
            # when CI runs
            public_project_id_sub = rf"\1{args.public_project_id}"
            query_arguments = PROJECT_ID_ARG_RE.sub(
                public_project_id_sub, query_arguments
            )
    except yaml.YAMLError as e:
        print(e)
        sys.exit(1)
    except FileNotFoundError as e:
        print("Metadata file does not exist: {}", e)

    with open(query_file) as query_stream:
        # run the query as shell command so that passed parameters can be used as is
        sql = query_stream.read()
        subprocess.call(["bq"] + query_arguments.split() + [sql])


if __name__ == "__main__":
    main()
