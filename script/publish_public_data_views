#!/usr/bin/env python3

"""
Generate view definitions for queries that are written to the
public data project and execute them. Views are published to
an internal project so that data is also accessible in private
datasets.
"""

from argparse import ArgumentParser
import os
import sys
import yaml

from google.cloud import bigquery

METADATA_FILE = "metadata.yaml"


parser = ArgumentParser(description=__doc__)
parser.add_argument(
    "--target",
    nargs="+",
    help="File or directory containing query definitions and metadata",
)
parser.add_argument("--target-project", help="Create views in the target project")
parser.add_argument(
    "--public-project",
    default="mozilla-public-data",
    help=("Project with publicly available data"),
)
parser.add_argument(
    "--dry_run",
    "--dry-run",
    action="store_true",
    help="Validate view definitions, but do not publish them.",
)


def is_public_bigquery(metadata_file):
    """
    Reads the metadata file associated with the query to determine if the query 
    results should be written into the public dataset.
    """

    try:
        with open(metadata_file, "r") as yaml_stream:
            try:
                metadata = yaml.safe_load(yaml_stream)

                if "labels" in metadata:
                    if "public_bigquery" in metadata["labels"]:
                        if metadata["labels"]["public_bigquery"] == True:
                            return True
            except yaml.YAMLError as e:
                print("Error reading metadata file: {}".format(metadata_file))
    except FileNotFoundError as e:
        print("Metadata file does not exist: {}", e)

    return False


def generate_and_publish_view(client, project, dataset, table, public_project, dry_run):
    """
    Generates view definitions for public data and executes them.
    """

    full_view_id = ".".join([project, dataset, table])
    public_table = ".".join([public_project, dataset, table])

    view_sql = f"""CREATE OR REPLACE VIEW 
        `{full_view_id}`
    AS SELECT * FROM `{public_table}`
    """

    job_config = bigquery.QueryJobConfig(use_legacy_sql=False, dry_run=dry_run)
    client.query(view_sql, job_config)


def main():
    args = parser.parse_args()
    target_project = args.target_project
    client = bigquery.Client(target_project)

    for target in args.target:
        if os.path.isdir(target):
            for root, dirs, files in os.walk(target):
                if METADATA_FILE in files:
                    metadata_file = os.path.join(root, METADATA_FILE)

                    if is_public_bigquery(metadata_file):
                        path = os.path.normpath(root)
                        dataset = path.split(os.sep)[-2]
                        table = path.split(os.sep)[-1]

                        generate_and_publish_view(
                            client,
                            target_project,
                            dataset,
                            table,
                            args.public_project,
                            args.dry_run,
                        )


if __name__ == "__main__":
    main()
