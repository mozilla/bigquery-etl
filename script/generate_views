#!/usr/bin/env python3

"""
Generate one view definition file per document type in '_stable' tables.

If there are existing view definitions in the destination directory then those will be
kept instead.

Run as:
  ./script/generate_views 'moz-fx-data-shared-prod:*_stable.*'
"""

from argparse import ArgumentParser
from fnmatch import fnmatchcase
import logging
import os
import re

from google.cloud import bigquery

VERSION_RE = re.compile(r"_v([0-9]+)$")
WHITESPACE_RE = re.compile(r"\s+")
WILDCARD_RE = re.compile(r"[*?[]")

DEFAULT_PATTERN = "telemetry.*"
DEFAULT_EXCLUDE = r"*_raw"

parser = ArgumentParser(description=__doc__)
parser.add_argument(
    "patterns",
    metavar="[project:]dataset[.table]",
    default=[DEFAULT_PATTERN],
    nargs="*",
    help="Table that should have a latest-version view, may use shell-style wildcards,"
    f" defaults to: {DEFAULT_PATTERN}",
)
parser.add_argument(
    "--exclude",
    action="append",
    default=[DEFAULT_EXCLUDE],
    metavar="project:dataset.table",
    help="Latest-version views that should be ignored, may use shell-style wildcards,"
    f" defaults to: {DEFAULT_EXCLUDE}",
)
parser.add_argument(
    "--sql-dir", default="sql/", help="The path where generated SQL files are stored."
)
parser.add_argument("--log-level", default="INFO", help="Defaults to INFO")


def uses_wildcards(pattern: str) -> bool:
    return bool(set("*?[]") & set(pattern))


def main():
    args = parser.parse_args()

    # set log level
    try:
        logging.basicConfig(level=args.log_level, format="%(levelname)s %(message)s")
    except ValueError as e:
        parser.error(f"argument --log-level: {e}")

    client = bigquery.Client()
    views = get_views(client, args.patterns)

    create_views_if_not_exist(views, args.exclude, args.sql_dir)


def get_views(client, patterns):
    all_projects = None
    all_datasets = {}
    all_tables = {}
    views = {}
    for pattern in patterns:
        project, _, dataset_table = pattern.partition(":")
        dataset, _, table = dataset_table.partition(".")
        projects = [project or client.project]
        dataset = dataset or "*"
        table = table or "*"
        if uses_wildcards(project):
            if all_projects is None:
                all_projects = [p.project_id for p in client.list_projects()]
            projects = [p for p in all_projects if fnmatchcase(project, p)]
        for project in projects:
            datasets = [dataset]
            if uses_wildcards(dataset):
                if project not in all_datasets:
                    all_datasets[project] = [
                        d.dataset_id for d in client.list_datasets(project)
                    ]
                datasets = [d for d in all_datasets[project] if fnmatchcase(d, dataset)]
            for dataset in datasets:
                dataset = f"{project}.{dataset}"
                tables = [(f"{dataset}.{table}", None)]
                if uses_wildcards(table):
                    if dataset not in all_tables:
                        all_tables[dataset] = list(client.list_tables(dataset))
                    tables = [
                        (f"{dataset}.{t.table_id}", t.table_type)
                        for t in all_tables[dataset]
                        if fnmatchcase(t.table_id, table)
                    ]
                for full_table_id, table_type in tables:
                    view = VERSION_RE.sub("", full_table_id)
                    if view not in views:
                        views[view] = {}
                    views[view][full_table_id] = table_type

    return views


def create_views_if_not_exist(views, exclude, sql_dir):
    # create views unless a local file for creating the view exists
    for view, tables in views.items():
        if any(fnmatchcase(pattern, view) for pattern in exclude):
            logging.info("skipping table: matched by exclude pattern: {view}")
            continue
        if view.endswith("_"):
            # A trailing '_' confuses the logic here of parsing versions,
            # and likely indicates that the table is somehow private, so
            # we ignore it.
            logging.info("skipping table ending in _: {view}")
            continue

        version = max(
            int(match.group()[2:])
            for table in tables
            for match in (VERSION_RE.search(table),)
            if match is not None
        )

        project, dataset, viewname = view.split(".")
        target = f"{view}_v{version}"
        view_query = f"SELECT * FROM\n  `{target}`"
        view_dataset = dataset.rsplit("_", 1)[0]
        full_view_id = ".".join([project, view_dataset, viewname])
        target_file = f"{sql_dir}/{view_dataset}/{viewname}/view.sql"
        full_sql = f"CREATE OR REPLACE VIEW\n  `{full_view_id}`\nAS {view_query}\n"

        if not os.path.exists(target_file):
            print("Creating " + target_file)
            if not os.path.exists(os.path.dirname(target_file)):
                os.makedirs(os.path.dirname(target_file))
            with open(target_file, "w") as f:
                f.write(full_sql)


if __name__ == "__main__":
    main()
