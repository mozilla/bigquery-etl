---
version: 2
jobs:
  build:
    docker: &docker
      - image: python:3.8
    steps:
      - checkout
      - &restore_venv_cache
        restore_cache:
          keys:
            # when lock files change, use increasingly general
            # patterns to restore cache
            - &python_cache_key
              # yamllint disable-line rule:line-length
              python-3.8-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-{{ checksum "requirements.txt" }}
              # yamllint disable-line rule:line-length
            - python-3.8-packages-v1-{{ .Branch }}-{{ checksum "requirements.in" }}-
            - python-3.8-packages-v1-{{ .Branch }}-
            - python-3.8-packages-v1-master-
            - python-3.8-packages-v1-
      - &build
        run:
          name: Build
          command: |
            python3.8 -m venv venv/
            venv/bin/pip install pip-tools --constraint requirements.in
            venv/bin/pip-sync
      - run:
          name: Yamllint Test
          command: PATH="venv/bin:$PATH" yamllint -c .yamllint.yaml .
      - run:
          name: PyTest with linters
          command: PATH="venv/bin:$PATH" script/entrypoint
      - save_cache:
          paths:
            - venv/
          key: *python_cache_key
  verify-format-sql:
    docker: *docker
    steps:
      - checkout
      - run:
          name: Verify that SQL is correctly formatted
          command: script/format_sql --check $(git ls-tree -d HEAD --name-only)
  verify-requirements:
    docker: *docker
    steps:
      - checkout
      - run:
          name: Verify that requirements.txt contains the right dependencies for
            this python version
          # use `--constraint` with `requirements.in` not `requirements.txt`
          # because for pip>=20.3 "Constraints are only allowed to take the form
          # of a package name and a version specifier"
          command: |
            pip install pip-tools --constraint requirements.in
            pip-compile --quiet --allow-unsafe --generate-hashes
            git diff --exit-code requirements.txt
  dry-run-sql:
    docker: *docker
    steps:
      - checkout
      - run:
          name: Verify that BigQuery validates each query
          command: script/dryrun
  validate-metadata:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - run:
          name: Verify that metadata files are valid
          command: PATH="venv/bin:$PATH" script/validate_metadata
  integration:
    docker: *docker
    steps:
      - checkout
      - &skip_forked_pr
        run:
          name: Early return if this build is from a forked PR
          command: |
            if [ -n "$CIRCLE_PR_NUMBER" ]; then
              echo "Cannot pass creds to forked PRs," \
                "so marking this step successful"
              circleci step halt
            fi
      - *restore_venv_cache
      - *build
      - &restore_mvn_cache
        restore_cache:
          keys:
            # when lock files change, use increasingly general
            # patterns to restore cache
            - &mvn_cache_key
              maven-packages-v1-{{ .Branch }}-{{ checksum "pom.xml" }}
            - maven-packages-v1-{{ .Branch }}-
            - maven-packages-v1-
      - &java_deps
        run:
          name: Install maven and java and download dependency jars
          command: |
            apt update
            apt install -y maven default-jdk-headless
            mvn dependency:copy-dependencies
      - run:
          name: PyTest Integration Test
          # Google's client libraries will check for
          # GOOGLE_APPLICATION_CREDENTIALS
          # and use a file in that location for credentials if present;
          # See https://cloud.google.com/docs/authentication/production
          command: |
            export GOOGLE_APPLICATION_CREDENTIALS="/tmp/gcp.json"
            echo "$GCLOUD_SERVICE_KEY" > "$GOOGLE_APPLICATION_CREDENTIALS"
            PATH="venv/bin:$PATH" script/entrypoint -m 'integration or java'
      - save_cache:
          paths:
            - ~/.m2
          key: *mvn_cache_key
  validate-dags:
    # based on
    # https://github.com/mozilla/telemetry-airflow/blob/master/.circleci/config.yml
    machine:
      image: ubuntu-1604:201903-01
      docker_layer_caching: true
    steps:
      - checkout
      - run:
          name: Early return when job not modified
          command: |
            if [ "$CIRCLE_BRANCH" = master ]; then
              echo "Run job because branch is $CIRCLE_BRANCH"
            elif git log --format=%B --no-merges -n 1 |
                grep -qF '[run-tests]'; then
              echo "Run job because [run-tests] in commit message"
            elif ! git diff --quiet origin/master... \
                -- "$(git rev-parse --show-toplevel)"/{.circleci,dags}; then
              echo "Run job because .circleci/ and/or dags/ were modified" \
                "since branching off master"
            else
              echo "Skipping job because .circleci/ and dags/ were not modified"
              circleci step halt
            fi
      - run:
          name: Pull telemetry-airflow
          command: |
            git clone https://github.com/mozilla/telemetry-airflow.git
            cp -a dags/. telemetry-airflow/dags/
      - run:
          command: |
            cd telemetry-airflow
            docker-compose pull
            docker-compose build
            # now take ownership of the folder
            sudo chown -R 10001:10001 .
      - run:
          name: Test if dag scripts can be parsed
          command: |
            cd telemetry-airflow
            bash bin/test-parse
  verify-dags-up-to-date:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - *restore_mvn_cache
      - *java_deps
      - run:
          name: Generate DAGs
          command: PATH="venv/bin:$PATH" script/generate_airflow_dags
      - run:
          name: Verify that DAGs were correctly generated and are up-to-date
          command: git diff --exit-code
  verify-queries-up-to-date:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      # Additional query generation commands may be added here in the future.
      - run:
          name: Generate events_daily Queries
          command: PATH="venv/bin:$PATH" script/generate_events_daily_queries
      - run:
          name: Verify that queries were correctly generated and are up-to-date
          command: git diff --exit-code
  validate-docs:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - run:
          name: Validate doc examples
          command: PATH="venv/bin:$PATH" script/validate_docs
  validate-views:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - *restore_mvn_cache
      - *java_deps
      - run:
          name: Validate views
          command: PATH="venv/bin:$PATH" script/validate_views
  validate-schemas:
    docker: *docker
    steps:
      - checkout
      - *build
      - run:
          name: Validate query schemas
          command: |
            pip install .
            bqetl query schema validate "*"
  docs:
    docker: *docker
    steps:
      - checkout
      - *skip_forked_pr
      - *restore_venv_cache
      - *build
      - attach_workspace:
          at: /tmp/generated-sql
      - run:
          name: Install dependencies
          command: >
            pip install mkdocs mkdocs-material markdown-include 
            mkdocs-awesome-pages-plugin
      - add_ssh_keys:
          fingerprints: "ab:b5:f7:55:92:0a:72:c4:63:0e:57:be:cd:66:32:53"
      - run:
          name: Build and deploy docs
          command: |
            rm -r sql/ && cp -r /tmp/generated-sql/sql sql/
            PATH="venv/bin:$PATH" script/generate_docs \
               --output_dir=generated_docs/
            cd generated_docs/
            mkdocs gh-deploy \
              -m "[ci skip] Deployed {sha} with MkDocs version: {version}"
  generate-sql:
    docker: *docker
    steps:
      - checkout
      - *restore_venv_cache
      - *build
      - run:
          name: Generate SQL content
          command: |
            mkdir /tmp/generated-sql
            cp -r sql/ /tmp/generated-sql/sql
            # Don't depend on dry run for PRs
            PATH="venv/bin:$PATH" ./script/generate_sql \
              --sql-dir /tmp/generated-sql/sql/ \
              --target-project moz-fx-data-shared-prod \
              $(test "${CIRCLE_BRANCH}" = master || echo --no-dry-run)
      - persist_to_workspace:
          root: /tmp/generated-sql
          paths:
            - sql
  push-generated-sql:
    docker: *docker
    steps:
      - attach_workspace:
          at: /tmp/generated-sql
      - add_ssh_keys:
          fingerprints: "ab:b5:f7:55:92:0a:72:c4:63:0e:57:be:cd:66:32:53"
      - run:
          name: Push to generated-sql branch
          command: |
            ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts
            git config --global user.name "CircleCI generate-sql job"
            git config --global user.email "dataops+generated-sql@mozilla.com"
            git clone --single-branch --branch generated-sql \
              git@github.com:mozilla/bigquery-etl \
              generated-sql
            cd generated-sql/
            rm -rf sql/
            cp -r /tmp/generated-sql/sql sql
            git add .
            git commit -m "Auto-push due to change on main branch [ci skip]" \
              && git push \
              || echo "Skipping push since it looks like there were no changes"
  deploy:
    parameters:
      image:
        type: string
    docker:
      # bash required for step: Determine docker image name
      - image: relud/docker-bash
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: true
      - run:
          name: Determine docker image name
          command:
          # yamllint disable-line rule:line-length
            echo 'IMAGE="${CIRCLE_PROJECT_USERNAME+$CIRCLE_PROJECT_USERNAME/}${CIRCLE_PROJECT_REPONAME:-bigquery-etl}:${CIRCLE_TAG:-latest}"' > $BASH_ENV
      - run:
          name: Build docker image
          command: docker build . --pull --tag "$IMAGE"
      - run:
          name: Deploy to Dockerhub
          command: |
           echo "${DOCKER_PASS:?}" | \
            docker login -u "${DOCKER_USER:?}" --password-stdin
            docker push "$IMAGE"

workflows:
  version: 2
  build:
    jobs:
      - build:
          context: data-eng-circleci-tests
      - verify-format-sql
      - verify-requirements
      - dry-run-sql
      - validate-metadata
      - integration
      - validate-dags
      - verify-dags-up-to-date
      - validate-docs
      - validate-views
      - generate-sql
      - docs:
          requires:
            - generate-sql
          filters:
            branches:
              only: master
      - push-generated-sql:
          requires:
            - generate-sql
          filters:
            branches:
              only:
                - master
      - deploy:
          context: data-eng-bigquery-etl-dockerhub
          requires:
            # can't run in parallel because CIRCLE_BUILD_NUM is same
            - build
          filters:
            branches:
              only: master
            tags:
              only: /.*/
