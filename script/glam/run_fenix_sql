#!/bin/bash
# Run the scalars sql job against all Glean pings in a product. Assumes that
# generate_fenix_sql has already been run.

set -e

PROJECT="glam-fenix-dev"
DATASET="glam_etl"


# `date` is not consistent across MacOS and GNU/Linux
function yesterday {
    python3 - <<EOD
from datetime import date, timedelta
dt = date.today() - timedelta(1)
print(dt.strftime("%Y-%m-%d"))
EOD
}


# NOTE: it may not even be necessary to include the project where the table is
# going to be created in the sql folder if the `--project_id` parameter is
# always passed to `bq query`.
function init_sql_replace_project {
    local sql_path=$1
    local prod="moz-fx-data-shared-prod"
    sed "s/$prod/$PROJECT/g" < "$sql_path"
}


function run_query {
    local destination_table=$1
    # optionally take a second argument for the query to run, otherwise default
    # to the name of the destination table
    local query=${2:-"sql/glam_etl/$destination_table/query.sql"}
    echo "running $query"
    bq query \
        --max_rows=0 \
        --use_legacy_sql=false \
        --replace \
        --project_id="$PROJECT" \
        --dataset_id="$DATASET" \
        --destination_table="$destination_table" \
        --parameter=submission_date:DATE:"$(yesterday)" \
        < "$query"
}


function run_init {
    local destination_table=$1
    local init="sql/glam_etl/$destination_table/init.sql"
    # run if needed
    if ! bq show --quiet "${DATASET}.${destination_table}"; then
        echo "running $init"
        bq query \
            --use_legacy_sql=false \
            --project_id="$PROJECT" \
            "$(init_sql_replace_project "$init" "$PROJECT" | sed 1d)"
            # bq thinks the comment in the first line is a flag...
    fi
}


function main {
    cd "$(dirname "$0")/../.."

    local start_stage=${START_STAGE:-0}
    local reset=${RESET:-false}

    # revert to the original default project in the environment
    original_project=$(gcloud config get-value project)
    function cleanup {
        gcloud config set project "$original_project"
    }
    trap cleanup EXIT

    gcloud config set project $PROJECT

    if $reset; then
        # force delete the dataset
        bq rm -r -f "$DATASET"
        bq mk "$DATASET"
    fi

    # NOTE: the append mechanism is a bit non-standard, it may be useful to have
    # a view using a wildcard table query instead. This will simplify the
    # automated DAG creation later.
    if ((start_stage <= 0)); then
        for query in sql/glam_etl/fenix_clients_daily*scalars*/query.sql; do
            run_query "fenix_clients_daily_scalar_aggregates_v1" "$query"
        done
    fi
    # NOTE: there isn't a mechanism to test the incremental query here
    if ((start_stage <= 1)); then
        run_query "fenix_latest_versions_v1"
        run_init "fenix_clients_scalar_aggregates_v1"
        run_query "fenix_clients_scalar_aggregates_v1"
    fi
    if ((start_stage <= 2)); then run_query "fenix_clients_scalar_bucket_counts_v1"; fi
    if ((start_stage <= 3)); then run_query "fenix_clients_scalar_probe_counts_v1"; fi
    if ((start_stage <= 4)); then run_query "fenix_scalar_percentiles_v1"; fi
}

main
