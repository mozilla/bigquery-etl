#!/usr/bin/env python3

"""
This script publishes all user-defined functions in udf/ as persistent UDFs in the udf dataset.

The udf_ prefix will be stripped from names of published UDFs.
"""

from argparse import ArgumentParser
import os
import sys
import re
from google.cloud import bigquery

# sys.path needs to be modified to enable package imports from parent
# and sibling directories. Also see:
# https://stackoverflow.com/questions/6323860/sibling-package-imports/23542795#23542795
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from bigquery_etl.parse_udf import (
    read_udf_dir,
    udf_usages_in_file,
    accumulate_dependencies,
)


UDF_RE = re.compile(r"udf_(?:js_)?([a-zA-z0-9_]+)")


parser = ArgumentParser(description=__doc__)
parser.add_argument(
    "--project-id", default="moz-fx-data-derived-datasets", help="The project ID."
)
parser.add_argument(
    "--dataset",
    default="udf",
    help="The name of the dataset the persistent UDFs will be stored in.",
)
parser.add_argument(
    "--udf-dir",
    default="udf/",
    help="The directory where declarations of temporary UDFs are stored.",
)


def main():
    args = parser.parse_args()

    raw_udfs = {x.name: x for x in read_udf_dir(args.udf_dir)}
    published_udfs = []
    client = bigquery.Client(args.project_id)

    for raw_udf in raw_udfs:
        # get all dependencies for UDF and publish as persistent UDF
        udfs_to_publish = accumulate_dependencies([], raw_udfs, raw_udf)
        udfs_to_publish.append(raw_udf)
        for dep in udfs_to_publish:
            if dep not in published_udfs:
                publish_persistent_udf(raw_udfs[dep], client, args.dataset, args.project_id)
                published_udfs.append(dep)


def publish_persistent_udf(raw_udf, client, dataset, project_id):
    # transforms temporary UDF to persistent UDFs and publishes them
    for definition in raw_udf.definitions:
        # Within a standard SQL function, references to other entities require explicit project IDs
        query_with_renamed_udfs = UDF_RE.sub(
            "`" + project_id + "`." + dataset + "." + r"\1", definition
        )
        query = query_with_renamed_udfs.replace(
            "CREATE TEMP FUNCTION", "CREATE OR REPLACE FUNCTION"
        )

        client.query(query)


if __name__ == "__main__":
    main()
