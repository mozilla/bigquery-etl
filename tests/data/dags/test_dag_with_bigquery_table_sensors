# Generated via https://github.com/mozilla/bigquery-etl/blob/main/bigquery_etl/query_scheduling/generate_airflow_dags.py

from airflow import DAG
from airflow.providers.google.cloud.sensors.bigquery import (
    BigQueryTableExistenceSensor,
    BigQueryTablePartitionExistenceSensor,
)
from airflow.sensors.external_task import ExternalTaskMarker
from airflow.sensors.external_task import ExternalTaskSensor
from airflow.utils.task_group import TaskGroup
import datetime
from operators.gcp_container_operator import GKEPodOperator
from utils.constants import ALLOWED_STATES, FAILED_STATES
from utils.gcp import bigquery_etl_query, bigquery_dq_check

docs = """
### bqetl_test_dag

Built from bigquery-etl repo, [`dags/bqetl_test_dag.py`](https://github.com/mozilla/bigquery-etl/blob/generated-sql/dags/bqetl_test_dag.py)

#### Owner

test@example.org

#### Tags

* repo/bigquery-etl
"""


default_args = {
    "owner": "test@example.org",
    "start_date": datetime.datetime(2020, 1, 1, 0, 0),
    "end_date": None,
    "email": ["test@example.org"],
    "depends_on_past": False,
    "retry_delay": datetime.timedelta(seconds=3600),
    "email_on_failure": True,
    "email_on_retry": True,
    "retries": 2,
}

tags = ["repo/bigquery-etl"]

with DAG(
    "bqetl_test_dag",
    default_args=default_args,
    schedule_interval="@daily",
    doc_md=docs,
    tags=tags,
) as dag:

    wait_for_foo_bar_baz = BigQueryTableExistenceSensor(
        task_id="wait_for_foo_bar_baz",
        project_id="foo",
        dataset_id="bar",
        table_id="baz_{{ ds_nodash }}",
        gcp_conn_id="google_cloud_shared_prod",
        deferrable=True,
        poke_interval=datetime.timedelta(seconds=1800),
        timeout=datetime.timedelta(seconds=43200),
        retries=1,
        retry_delay=datetime.timedelta(seconds=600),
    )

    wait_for_foo_bar_baz_partition = BigQueryTablePartitionExistenceSensor(
        task_id="wait_for_foo_bar_baz_partition",
        project_id="foo",
        dataset_id="bar",
        table_id="baz",
        partition_id="{{ ds_nodash }}",
        gcp_conn_id="google_cloud_shared_prod",
        deferrable=True,
        poke_interval=datetime.timedelta(seconds=900),
        timeout=datetime.timedelta(seconds=21600),
        retries=3,
        retry_delay=datetime.timedelta(seconds=300),
    )

    test__non_incremental_query__v1 = bigquery_etl_query(
        task_id="test__non_incremental_query__v1",
        destination_table="non_incremental_query_v1",
        dataset_id="test",
        project_id="moz-fx-data-test-project",
        owner="test@example.com",
        email=["test@example.com"],
        date_partition_parameter="submission_date",
        depends_on_past=True,
        arguments=["--append_table"],
    )

    test__non_incremental_query__v1.set_upstream(wait_for_foo_bar_baz)

    test__non_incremental_query__v1.set_upstream(wait_for_foo_bar_baz_partition)
